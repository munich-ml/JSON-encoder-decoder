{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "JSON_datatypes.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPKumklxKOI9JQjDOr2NyBK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/munich-ml/file_IO/blob/master/JSON_datatypes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rz9dSwYd7cuG",
        "colab_type": "text"
      },
      "source": [
        "# Motivation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9E1ylLJq989",
        "colab_type": "text"
      },
      "source": [
        "**JSON** is a very popular for storing structured data in (.json) files. IO libraries for JSON handling exist for most programming languages. In Python `json` is the standard module providing write `json.dump()` and read `json.load()` functionality.\n",
        "\n",
        "A limitation that I regularly encountered is the support of just basic Python datatypes: ``int``, ``float``, ``str``, ``bool``, ``None``, ``list``, (``tuple``), ``dict``.  I put ``tuple`` in parenthesis, because they are converted to ``list``. Thus I consider them just partially supported, but that doesn't bother me too much. More painful is the lack of powerful but common datatypes like `datetime.datetime` or `pandas.DataFrame`.\n",
        "\n",
        "Therefore, a custom JSON encoder and decoder pair is implemented in here, that supports:\n",
        "- ``pandas.DataFrame`` and ``pandas.Series``,\n",
        "- ``numpy.array``,\n",
        "- ``datetime.datetime`` and ``datetime.timedelta``\n",
        "\n",
        "More datatypes can easily be added."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVqqDTVm7hTL",
        "colab_type": "text"
      },
      "source": [
        "# Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0F7ouetTHDQV",
        "colab_type": "text"
      },
      "source": [
        "We import `json`, of course, as well as `numpy`, `pandas` and `matplotlib`, because those modules contain the datatypes that we want to support. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAi1AybO24Sd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "import json"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fa1LbxsYHmKH",
        "colab_type": "text"
      },
      "source": [
        "### Custom JSON encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3CgT3gDqWjH",
        "colab_type": "text"
      },
      "source": [
        "According to https://docs.python.org/3/library/json.html we implement a **custom encoder `JsonEnc`** by subclassing the **default encoder `json.JSONEncoder`**. \n",
        "\n",
        "Each **additional datatype** will be represented using the JSON's **standard datatypes**. Unique keys are used to allow reconstruction of the original datatype within the Decoder. The unique keys are:\n",
        "- ``\"@DataFrame\"``\n",
        "- ``\"@Series\"``\n",
        "- ``\"@np.array\"``\n",
        "- ``\"@datetime\"``\n",
        "- ``\"@timedelta\"`` \n",
        "\n",
        "Let's look at ``datetime.timedelta`` encoding as example:\n",
        "```python\n",
        "if isinstance(obj, dt.timedelta):\n",
        "    return {\"@timedelta\": obj.total_seconds()}\n",
        "```\n",
        "A `datetime.timedelta` object is encoded into a `dict` holding exactly 1 item with \n",
        "- the keyword `str` `@timedelta` as dictionary key, and \n",
        "- the `float` `total_seconds` as dictionary value.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sD14E6un3VKt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class JsonEnc(json.JSONEncoder):\n",
        "    \"\"\"\n",
        "    Extends the standard JSONEncoder to support additional datatypes.\n",
        "    \n",
        "    Keywords strings as dict keys are used to identify instances of the \n",
        "    additional types.\n",
        "    \n",
        "    Additional datatype  | keyword\n",
        "    ---------------------|------------\n",
        "    pandas DataFrame     | @DataFrame\n",
        "    pandas Series        | @Series\n",
        "    numpy array          | @np.array\n",
        "    datetime.datetime    | @datetime\n",
        "    datetime.timedelta   | @timedelta\n",
        "    \n",
        "    Of course, the regular JSON datatypes are supported, too:\n",
        "        int, float, str, bool, None, list, (tuple), dict\n",
        "        \n",
        "    Example usage:\n",
        "        # Encode data object to json_str\n",
        "        json_str = json.dumps(data, cls=JsonEnc)\n",
        "        \n",
        "        # Decode json_str to a data object\n",
        "        data_copy = json.loads(json_str, cls=JsonDec)\n",
        "        \n",
        "    \"\"\"\n",
        "    def default(self, obj):\n",
        "        if isinstance(obj, pd.DataFrame):\n",
        "            return {\"@DataFrame\": {\"columns\": list(obj.columns),\n",
        "                                   \"index\": list(obj.index),\n",
        "                                   \"data\": obj.values.tolist()}}\n",
        "        \n",
        "        if isinstance(obj, pd.Series):\n",
        "            return {\"@Series\": {\"name\": obj.name,\n",
        "                                \"index\": list(obj.index),\n",
        "                                \"data\": obj.values.tolist()}}\n",
        "        \n",
        "        if isinstance(obj, np.ndarray):\n",
        "            return {\"@np.array\": obj.tolist()}\n",
        "        \n",
        "        if isinstance(obj, dt.datetime):\n",
        "            return {\"@datetime\": obj.strftime('%Y-%m-%d %H:%M:%S.%f')}\n",
        "\n",
        "        if isinstance(obj, dt.timedelta):\n",
        "            return {\"@timedelta\": obj.total_seconds()}\n",
        "\n",
        "        return json.JSONEncoder.default(self, obj)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsQi936oLwvd",
        "colab_type": "text"
      },
      "source": [
        "### Custom JSON decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjVHTN7lqcBd",
        "colab_type": "text"
      },
      "source": [
        "The **custom decoder `JsonDec`** is implemented by subclassing the **default decoder `json.JSONDecoder`**. \n",
        "\n",
        "The custom part of the decoder **JsonDec** is triggered by the **keywords** injected by the custom encoder **JsonEnc**: \n",
        "\n",
        "Again, let's look at the `datetime.timedelta` example:\n",
        "```python\n",
        "if len(dct) == 1:\n",
        "    if \"@timedelta\" in dct:\n",
        "        return dt.timedelta(seconds=dct[\"@timedelta\"])\n",
        "return dct\n",
        "```\n",
        "A `datetime.timedelta` object is encoded into a `dict` holding exactly 1 item with \n",
        "- the keyword `str` `@timedelta` as dictionary key, and \n",
        "- the `float` `total_seconds` as dictionary value.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4oUGvNA3UrE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class JsonDec(json.JSONDecoder):\n",
        "    \"\"\"\n",
        "    Extends the standard JSONDecoder to support additional datatypes.\n",
        "    \n",
        "    Additional types are recognized by dict key keywords, which are injected \n",
        "    by the JsonEnc.\n",
        "    \n",
        "    Additional datatype  | keyword\n",
        "    ---------------------|------------\n",
        "    pandas DataFrame     | @DataFrame\n",
        "    pandas Series        | @Series\n",
        "    numpy array          | @np.array\n",
        "    datetime.datetime    | @datetime\n",
        "    datetime.timedelta   | @timedelta\n",
        "    \n",
        "    Of course, the regular JSON datatypes are supported, too:\n",
        "        int, float, str, bool, None, list, (tuple), dict\n",
        "        \n",
        "    Example usage:\n",
        "        # Encode data object to json_str\n",
        "        json_str = json.dumps(data, cls=JsonEnc)\n",
        "        \n",
        "        # Decode json_str to a data object\n",
        "        data_copy = json.loads(json_str, cls=JsonDec)\n",
        "        \n",
        "    \"\"\"\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(object_hook=JsonDec.custom_hook, *args, **kwargs)\n",
        "    \n",
        "    @staticmethod\n",
        "    def custom_hook(dct):\n",
        "        if len(dct) == 1:  # add. datatypes are coded in dict of len=1\n",
        "            if \"@np.array\" in dct:\n",
        "                return np.array(dct[\"@np.array\"])\n",
        "            \n",
        "            if \"@DataFrame\" in dct:\n",
        "                return pd.DataFrame(data=dct[\"@DataFrame\"][\"data\"],\n",
        "                                    columns=dct[\"@DataFrame\"][\"columns\"],\n",
        "                                    index=dct[\"@DataFrame\"][\"index\"])\n",
        "            \n",
        "            if \"@Series\" in dct:\n",
        "                return pd.Series(data=dct[\"@Series\"][\"data\"],\n",
        "                                 name=dct[\"@Series\"][\"name\"],\n",
        "                                 index=dct[\"@Series\"][\"index\"])\n",
        "            \n",
        "            if \"@datetime\" in dct:\n",
        "                return dt.datetime.strptime(dct[\"@datetime\"],\n",
        "                                            '%Y-%m-%d %H:%M:%S.%f')\n",
        "            \n",
        "            if \"@timedelta\" in dct:\n",
        "                return dt.timedelta(seconds=dct[\"@timedelta\"])\n",
        "            \n",
        "        return dct"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdrRaVcZ7lFg",
        "colab_type": "text"
      },
      "source": [
        "# Verification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pwohEwy84v-",
        "colab_type": "text"
      },
      "source": [
        "### Create test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXQDgRkE7uat",
        "colab_type": "text"
      },
      "source": [
        "Firstly, we wirte a function `create_example_container` that returns a test dictionary containing all additional datatypes supported by the custom JSON encoder/decoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zFbCFVx3UmX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "7cd8e89f-e13a-4ec8-e667-2b60b01df12c"
      },
      "source": [
        "def create_example_container():    \n",
        "    \"\"\"\n",
        "    Returns an example container as dict with all supported additional\n",
        "    datatypes.\n",
        "    \"\"\"\n",
        "    nCols, nRows = 3, 4\n",
        "    df1 = pd.DataFrame(np.random.randint(0, high=10, size=(nRows, nCols)),\n",
        "                        columns=[\"col\"+str(i) for i in range(nCols)],\n",
        "                        index=[\"idx\"+str(i) for i in range(nRows)])\n",
        "    \n",
        "    df2 = pd.DataFrame({\"dates\": [dt.datetime(2020, 6, 18), \n",
        "                                  dt.datetime(2020, 6, 22, 1, 2, 3)],\n",
        "                        \"values\": [42, True]})\n",
        "    df2[\"timedeltas\"] = dt.datetime.now() - df2[\"dates\"]\n",
        "    \n",
        "    return {\"regular_json\": [\"string\", 1, 2.33, None, False],\n",
        "            \"some_datetime\": dt.datetime.now(),\n",
        "            \"some_timedelta\": dt.timedelta(days=1, seconds=100),\n",
        "            \"some_np_array\": np.eye(3),\n",
        "            \"some_DateFrame\": df1,\n",
        "            \"DataFrame_with_dt\": df2,\n",
        "            \"some_Series\": df2[\"values\"]}\n",
        "\n",
        "# Example usage\n",
        "# 1. create an example dict with all additional datatypes\n",
        "data = create_example_container()\n",
        "data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'DataFrame_with_dt':                 dates values               timedeltas\n",
              " 0 2020-06-18 00:00:00     42   0 days 18:17:49.123795\n",
              " 1 2020-06-22 01:02:03   True -4 days +17:15:46.123795,\n",
              " 'regular_json': ['string', 1, 2.33, None, False],\n",
              " 'some_DateFrame':       col0  col1  col2\n",
              " idx0     6     2     4\n",
              " idx1     4     1     9\n",
              " idx2     0     6     5\n",
              " idx3     1     8     6,\n",
              " 'some_Series': 0      42\n",
              " 1    True\n",
              " Name: values, dtype: object,\n",
              " 'some_datetime': datetime.datetime(2020, 6, 18, 18, 17, 49, 129285),\n",
              " 'some_np_array': array([[1., 0., 0.],\n",
              "        [0., 1., 0.],\n",
              "        [0., 0., 1.]]),\n",
              " 'some_timedelta': datetime.timedelta(1, 100)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jL4aie5qCysh",
        "colab_type": "text"
      },
      "source": [
        "Ok, the `data` object contains at least on instance of all additionally supported datatypes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hXfM4HF8_oN",
        "colab_type": "text"
      },
      "source": [
        "### Save JSON file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlAi7vFp9p0q",
        "colab_type": "text"
      },
      "source": [
        "For saving the `data` object to file, we can use the regular `json.dump` / `json.dumps` methods. \n",
        "\n",
        "The **custom encoder `JsonEnc`** is handed over to the `cls` keyword argument. The docstring says:\n",
        "\n",
        "> *To use a custom ``JSONEncoder`` subclass (e.g. one that overrides the ``.default()`` method to serialize additional types), specify it with the ``cls`` kwarg; otherwise ``JSONEncoder`` is used.*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sh6mQrMf8fMu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"data.json\", \"w\") as f:\n",
        "    json.dump(data, f, cls=JsonEnc)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XY0B4sP0_dvA",
        "colab_type": "text"
      },
      "source": [
        "Let's double-check how the actual JSON string looks like, using `json.dumps`.\n",
        "\n",
        "For the sake of pretty-printing I use `indent=4`, which I don't recommend when dumping to files. The file size would be significantly larger (up to factor 10 for large integer tables) compared to the *on-liner-JSON* from `indent=None`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcuWij2i3Qpp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "61b7a21c-14f3-4f41-bbeb-b71165a34a8a"
      },
      "source": [
        "print(json.dumps(data, cls=JsonEnc, indent=4))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"regular_json\": [\n",
            "        \"string\",\n",
            "        1,\n",
            "        2.33,\n",
            "        null,\n",
            "        false\n",
            "    ],\n",
            "    \"some_datetime\": {\n",
            "        \"@datetime\": \"2020-06-18 18:17:49.129285\"\n",
            "    },\n",
            "    \"some_timedelta\": {\n",
            "        \"@timedelta\": 86500.0\n",
            "    },\n",
            "    \"some_np_array\": {\n",
            "        \"@np.array\": [\n",
            "            [\n",
            "                1.0,\n",
            "                0.0,\n",
            "                0.0\n",
            "            ],\n",
            "            [\n",
            "                0.0,\n",
            "                1.0,\n",
            "                0.0\n",
            "            ],\n",
            "            [\n",
            "                0.0,\n",
            "                0.0,\n",
            "                1.0\n",
            "            ]\n",
            "        ]\n",
            "    },\n",
            "    \"some_DateFrame\": {\n",
            "        \"@DataFrame\": {\n",
            "            \"columns\": [\n",
            "                \"col0\",\n",
            "                \"col1\",\n",
            "                \"col2\"\n",
            "            ],\n",
            "            \"index\": [\n",
            "                \"idx0\",\n",
            "                \"idx1\",\n",
            "                \"idx2\",\n",
            "                \"idx3\"\n",
            "            ],\n",
            "            \"data\": [\n",
            "                [\n",
            "                    6,\n",
            "                    2,\n",
            "                    4\n",
            "                ],\n",
            "                [\n",
            "                    4,\n",
            "                    1,\n",
            "                    9\n",
            "                ],\n",
            "                [\n",
            "                    0,\n",
            "                    6,\n",
            "                    5\n",
            "                ],\n",
            "                [\n",
            "                    1,\n",
            "                    8,\n",
            "                    6\n",
            "                ]\n",
            "            ]\n",
            "        }\n",
            "    },\n",
            "    \"DataFrame_with_dt\": {\n",
            "        \"@DataFrame\": {\n",
            "            \"columns\": [\n",
            "                \"dates\",\n",
            "                \"values\",\n",
            "                \"timedeltas\"\n",
            "            ],\n",
            "            \"index\": [\n",
            "                0,\n",
            "                1\n",
            "            ],\n",
            "            \"data\": [\n",
            "                [\n",
            "                    {\n",
            "                        \"@datetime\": \"2020-06-18 00:00:00.000000\"\n",
            "                    },\n",
            "                    42,\n",
            "                    {\n",
            "                        \"@timedelta\": 65869.123795\n",
            "                    }\n",
            "                ],\n",
            "                [\n",
            "                    {\n",
            "                        \"@datetime\": \"2020-06-22 01:02:03.000000\"\n",
            "                    },\n",
            "                    true,\n",
            "                    {\n",
            "                        \"@timedelta\": -283453.876205\n",
            "                    }\n",
            "                ]\n",
            "            ]\n",
            "        }\n",
            "    },\n",
            "    \"some_Series\": {\n",
            "        \"@Series\": {\n",
            "            \"name\": \"values\",\n",
            "            \"index\": [\n",
            "                0,\n",
            "                1\n",
            "            ],\n",
            "            \"data\": [\n",
            "                42,\n",
            "                true\n",
            "            ]\n",
            "        }\n",
            "    }\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4leYFAeAwbJ",
        "colab_type": "text"
      },
      "source": [
        "One can see the custom dict keys (e.g. `@Series`, `@DataFrame`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHGJYRmw9JA8",
        "colab_type": "text"
      },
      "source": [
        "### Load JSON file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3Vny8RLEQlm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "json.load?"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmltpj_QDEpC",
        "colab_type": "text"
      },
      "source": [
        "Again, the regular class methods `json.load` / `json.loads` methods can be used, but with the **custom decoder `JsonDec`**, handed over with the `cls` keyword argument. The docstring says:\n",
        "\n",
        "> *To use a custom ``JSONDecoder`` subclass, specify it with the ``cls`` kwarg; otherwise ``JSONDecoder`` is used.*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phXoIYZ98U6U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"data.json\", \"r\") as f:\n",
        "    data_copy = json.load(f, cls=JsonDec)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNaImK4j9NtK",
        "colab_type": "text"
      },
      "source": [
        "### Both containers equal?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY819W_3FGVr",
        "colab_type": "text"
      },
      "source": [
        "Unfortunatelly we can't test for equality the simple way: `data == data_copy`\n",
        "This is because equality of arrays or DataFrames is ambiguous, unless we test their values with `array.all()`.\n",
        "\n",
        "For the sake of simplicity, let's check the printouts visually ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSUtqq7t5ZVF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "c2ec4d3d-0b50-4f86-b2e1-9f0f1a140d71"
      },
      "source": [
        "data"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'DataFrame_with_dt':                 dates values               timedeltas\n",
              " 0 2020-06-18 00:00:00     42   0 days 18:17:49.123795\n",
              " 1 2020-06-22 01:02:03   True -4 days +17:15:46.123795,\n",
              " 'regular_json': ['string', 1, 2.33, None, False],\n",
              " 'some_DateFrame':       col0  col1  col2\n",
              " idx0     6     2     4\n",
              " idx1     4     1     9\n",
              " idx2     0     6     5\n",
              " idx3     1     8     6,\n",
              " 'some_Series': 0      42\n",
              " 1    True\n",
              " Name: values, dtype: object,\n",
              " 'some_datetime': datetime.datetime(2020, 6, 18, 18, 17, 49, 129285),\n",
              " 'some_np_array': array([[1., 0., 0.],\n",
              "        [0., 1., 0.],\n",
              "        [0., 0., 1.]]),\n",
              " 'some_timedelta': datetime.timedelta(1, 100)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2ORLXr_5Z70",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "6e169377-1dd4-44da-8b99-b5cf97f9d756"
      },
      "source": [
        "data_copy"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'DataFrame_with_dt':                 dates values               timedeltas\n",
              " 0 2020-06-18 00:00:00     42   0 days 18:17:49.123795\n",
              " 1 2020-06-22 01:02:03   True -4 days +17:15:46.123795,\n",
              " 'regular_json': ['string', 1, 2.33, None, False],\n",
              " 'some_DateFrame':       col0  col1  col2\n",
              " idx0     6     2     4\n",
              " idx1     4     1     9\n",
              " idx2     0     6     5\n",
              " idx3     1     8     6,\n",
              " 'some_Series': 0      42\n",
              " 1    True\n",
              " Name: values, dtype: object,\n",
              " 'some_datetime': datetime.datetime(2020, 6, 18, 18, 17, 49, 129285),\n",
              " 'some_np_array': array([[1., 0., 0.],\n",
              "        [0., 1., 0.],\n",
              "        [0., 0., 1.]]),\n",
              " 'some_timedelta': datetime.timedelta(1, 100)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3Q80L3E6_aC",
        "colab_type": "text"
      },
      "source": [
        "Although the printout of those `data` and `data_copy` dictionaries isn't pretty, one can see that both are identical."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U73fejko9Y2f",
        "colab_type": "text"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "``JsonEnc`` and ``JsonDec`` work just fine."
      ]
    }
  ]
}